{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepSpeech_Project.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOh6/H4Q5xOfuQsrWCMqHxy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frankx1/deepspeech_project/blob/main/DeepSpeech_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sPLitwAwWUM",
        "outputId": "650217f3-4124-4f57-caa8-896443a871cb"
      },
      "source": [
        "!pip install gitpython\n",
        "!pip install virtualenv\n",
        "import git\n",
        "import os\n",
        "\n",
        "git.Repo.clone_from('https://github.com/mozilla/DeepSpeech','DeepSpeech')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gitpython\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/d1/a7f8fe3df258549b303415157328bfcc63e9b11d06a7ad7a3327f3d32606/GitPython-3.1.11-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 5.4MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 4.0MB/s \n",
            "\u001b[?25hCollecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Installing collected packages: smmap, gitdb, gitpython\n",
            "Successfully installed gitdb-4.0.5 gitpython-3.1.11 smmap-3.0.4\n",
            "Collecting virtualenv\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/88/66ac964ab8cf87c8db839c11812292a966825af205411cb67477cb4e73d3/virtualenv-20.2.1-py2.py3-none-any.whl (4.9MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9MB 5.4MB/s \n",
            "\u001b[?25hCollecting distlib<1,>=0.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/0a/490fa011d699bb5a5f3a0cf57de82237f52a6db9d40f33c53b2736c9a1f9/distlib-0.3.1-py2.py3-none-any.whl (335kB)\n",
            "\u001b[K     |████████████████████████████████| 337kB 37.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources>=1.0; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from virtualenv) (3.3.0)\n",
            "Requirement already satisfied: six<2,>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from virtualenv) (1.15.0)\n",
            "Collecting appdirs<2,>=1.4.3\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/00/2344469e2084fb287c2e0b57b72910309874c3245463acd6cf5e3db69324/appdirs-1.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: filelock<4,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from virtualenv) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from virtualenv) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources>=1.0; python_version < \"3.7\"->virtualenv) (3.4.0)\n",
            "Installing collected packages: distlib, appdirs, virtualenv\n",
            "Successfully installed appdirs-1.4.4 distlib-0.3.1 virtualenv-20.2.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<git.repo.base.Repo '/content/DeepSpeech/.git'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJjVm_hu7YdQ",
        "outputId": "d6dd3e01-1210-4fbf-d1ba-16c844f3bc38"
      },
      "source": [
        "!apt-get install python3-venv\n",
        "!python3 -m venv /content/deepspeech-train-venv/\n",
        "!source /content/deepspeech-train-venv/bin/activate"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python-pip-whl python3.6-venv\n",
            "The following NEW packages will be installed:\n",
            "  python-pip-whl python3-venv python3.6-venv\n",
            "0 upgraded, 3 newly installed, 0 to remove and 14 not upgraded.\n",
            "Need to get 1,660 kB of archives.\n",
            "After this operation, 1,902 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-pip-whl all 9.0.1-2.3~ubuntu1.18.04.4 [1,653 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3.6-venv amd64 3.6.9-1~18.04ubuntu1.3 [6,180 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3-venv amd64 3.6.7-1~18.04 [1,208 B]\n",
            "Fetched 1,660 kB in 3s (657 kB/s)\n",
            "Selecting previously unselected package python-pip-whl.\n",
            "(Reading database ... 144865 files and directories currently installed.)\n",
            "Preparing to unpack .../python-pip-whl_9.0.1-2.3~ubuntu1.18.04.4_all.deb ...\n",
            "Unpacking python-pip-whl (9.0.1-2.3~ubuntu1.18.04.4) ...\n",
            "Selecting previously unselected package python3.6-venv.\n",
            "Preparing to unpack .../python3.6-venv_3.6.9-1~18.04ubuntu1.3_amd64.deb ...\n",
            "Unpacking python3.6-venv (3.6.9-1~18.04ubuntu1.3) ...\n",
            "Selecting previously unselected package python3-venv.\n",
            "Preparing to unpack .../python3-venv_3.6.7-1~18.04_amd64.deb ...\n",
            "Unpacking python3-venv (3.6.7-1~18.04) ...\n",
            "Setting up python-pip-whl (9.0.1-2.3~ubuntu1.18.04.4) ...\n",
            "Setting up python3.6-venv (3.6.9-1~18.04ubuntu1.3) ...\n",
            "Setting up python3-venv (3.6.7-1~18.04) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XipNFZdK9bSB",
        "outputId": "2b1a7ffb-327c-439a-d5ea-b8ee823d0290"
      },
      "source": [
        "os.chdir('DeepSpeech')\n",
        "!pip3 install --upgrade pip==20.2.2 wheel==0.34.2 setuptools==49.6.0\n",
        "!pip3 install --upgrade -e ."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pip==20.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/4a/39400ff9b36e719bdf8f31c99fe1fa7842a42fa77432e584f707a5080063/pip-20.2.2-py2.py3-none-any.whl (1.5MB)\n",
            "\r\u001b[K     |▏                               | 10kB 16.6MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 17.7MB/s eta 0:00:01\r\u001b[K     |▋                               | 30kB 10.1MB/s eta 0:00:01\r\u001b[K     |▉                               | 40kB 8.2MB/s eta 0:00:01\r\u001b[K     |█                               | 51kB 4.2MB/s eta 0:00:01\r\u001b[K     |█▎                              | 61kB 4.8MB/s eta 0:00:01\r\u001b[K     |█▌                              | 71kB 4.9MB/s eta 0:00:01\r\u001b[K     |█▊                              | 81kB 5.2MB/s eta 0:00:01\r\u001b[K     |██                              | 92kB 5.5MB/s eta 0:00:01\r\u001b[K     |██▏                             | 102kB 4.1MB/s eta 0:00:01\r\u001b[K     |██▍                             | 112kB 4.1MB/s eta 0:00:01\r\u001b[K     |██▋                             | 122kB 4.1MB/s eta 0:00:01\r\u001b[K     |██▉                             | 133kB 4.1MB/s eta 0:00:01\r\u001b[K     |███                             | 143kB 4.1MB/s eta 0:00:01\r\u001b[K     |███▎                            | 153kB 4.1MB/s eta 0:00:01\r\u001b[K     |███▌                            | 163kB 4.1MB/s eta 0:00:01\r\u001b[K     |███▊                            | 174kB 4.1MB/s eta 0:00:01\r\u001b[K     |████                            | 184kB 4.1MB/s eta 0:00:01\r\u001b[K     |████▏                           | 194kB 4.1MB/s eta 0:00:01\r\u001b[K     |████▍                           | 204kB 4.1MB/s eta 0:00:01\r\u001b[K     |████▋                           | 215kB 4.1MB/s eta 0:00:01\r\u001b[K     |████▉                           | 225kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████                           | 235kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 245kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 256kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 266kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 276kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 286kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 296kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 307kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 317kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████                         | 327kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 337kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 348kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 358kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 368kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 378kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 389kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 399kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 409kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████                       | 419kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 430kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 440kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 450kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 460kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████                      | 471kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 481kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 491kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 501kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 512kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 522kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 532kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 542kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 552kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████                    | 563kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 573kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 583kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 593kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 604kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 614kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 624kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 634kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 645kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 655kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 665kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 675kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 686kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 696kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 706kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 716kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 727kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 737kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 747kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 757kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 768kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 778kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 788kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 798kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 808kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 819kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 829kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 839kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 849kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 860kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 870kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 880kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 890kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 901kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 911kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 921kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 931kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 942kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 952kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 962kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 972kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 983kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 993kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.0MB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.0MB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.0MB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.0MB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.0MB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.1MB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.1MB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.1MB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.1MB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.1MB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.1MB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.1MB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1MB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.1MB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.1MB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.2MB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.2MB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.2MB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.2MB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.2MB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.2MB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2MB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.2MB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.2MB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.2MB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.3MB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.3MB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.3MB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.3MB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.3MB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.3MB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.3MB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.3MB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.3MB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.4MB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.4MB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.4MB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.4MB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.4MB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.4MB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.4MB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.4MB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.4MB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.4MB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.5MB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.5MB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.5MB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.5MB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.5MB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5MB 4.1MB/s \n",
            "\u001b[?25hCollecting wheel==0.34.2\n",
            "  Downloading https://files.pythonhosted.org/packages/8c/23/848298cccf8e40f5bbb59009b32848a4c38f4e7f3364297ab3c3e2e2cd14/wheel-0.34.2-py2.py3-none-any.whl\n",
            "Collecting setuptools==49.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/a9/5dc32465951cf4812e9e93b4ad2d314893c2fa6d5f66ce5c057af6e76d85/setuptools-49.6.0-py3-none-any.whl (803kB)\n",
            "\u001b[K     |████████████████████████████████| 808kB 39.1MB/s \n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip, wheel, setuptools\n",
            "  Found existing installation: pip 19.3.1\n",
            "    Uninstalling pip-19.3.1:\n",
            "      Successfully uninstalled pip-19.3.1\n",
            "  Found existing installation: wheel 0.35.1\n",
            "    Uninstalling wheel-0.35.1:\n",
            "      Successfully uninstalled wheel-0.35.1\n",
            "  Found existing installation: setuptools 50.3.2\n",
            "    Uninstalling setuptools-50.3.2:\n",
            "      Successfully uninstalled setuptools-50.3.2\n",
            "Successfully installed pip-20.2.2 setuptools-49.6.0 wheel-0.34.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/DeepSpeech\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.0a10) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: progressbar2 in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.0a10) (3.38.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.0a10) (1.15.0)\n",
            "Collecting pyxdg\n",
            "  Downloading pyxdg-0.27-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 2.5 MB/s \n",
            "\u001b[?25hCollecting attrdict\n",
            "  Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied, skipping upgrade: absl-py in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.0a10) (0.10.0)\n",
            "Collecting semver\n",
            "  Downloading semver-2.13.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting opuslib==2.0.0\n",
            "  Downloading opuslib-2.0.0.tar.gz (7.3 kB)\n",
            "Collecting optuna\n",
            "  Downloading optuna-2.3.0.tar.gz (258 kB)\n",
            "\u001b[K     |████████████████████████████████| 258 kB 8.0 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sox\n",
            "  Downloading sox-1.4.1-py2.py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied, skipping upgrade: bs4 in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.0a10) (0.0.1)\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.0a10) (1.1.4)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.0a10) (2.23.0)\n",
            "Collecting numba==0.47.0\n",
            "  Downloading numba-0.47.0-cp36-cp36m-manylinux1_x86_64.whl (3.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7 MB 19.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: llvmlite==0.31.0 in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.0a10) (0.31.0)\n",
            "Requirement already satisfied, skipping upgrade: librosa in /usr/local/lib/python3.6/dist-packages (from deepspeech-training==0.9.0a10) (0.6.3)\n",
            "Collecting soundfile\n",
            "  Downloading SoundFile-0.10.3.post1-py2.py3-none-any.whl (21 kB)\n",
            "Collecting ds_ctcdecoder==0.9.0-alpha.10\n",
            "  Downloading ds_ctcdecoder-0.9.0a10-cp36-cp36m-manylinux1_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 41.8 MB/s \n",
            "\u001b[?25hCollecting tensorflow==1.15.4\n",
            "  Downloading tensorflow-1.15.4-cp36-cp36m-manylinux2010_x86_64.whl (110.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5 MB 24 kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: python-utils>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from progressbar2->deepspeech-training==0.9.0a10) (2.4.0)\n",
            "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /simple/cmaes/\u001b[0m\n",
            "Collecting cmaes>=0.6.0\n",
            "  Downloading cmaes-0.7.0-py3-none-any.whl (13 kB)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-4.6.2-py2.py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from optuna->deepspeech-training==0.9.0a10) (4.41.1)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.4.3-py2.py3-none-any.whl (159 kB)\n",
            "\u001b[K     |████████████████████████████████| 159 kB 50.1 MB/s \n",
            "\u001b[?25hCollecting cliff\n",
            "  Downloading cliff-3.5.0-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 8.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from optuna->deepspeech-training==0.9.0a10) (0.17.0)\n",
            "Requirement already satisfied, skipping upgrade: sqlalchemy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from optuna->deepspeech-training==0.9.0a10) (1.3.20)\n",
            "Requirement already satisfied, skipping upgrade: scipy!=1.4.0 in /usr/local/lib/python3.6/dist-packages (from optuna->deepspeech-training==0.9.0a10) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: packaging>=20.0 in /usr/local/lib/python3.6/dist-packages (from optuna->deepspeech-training==0.9.0a10) (20.4)\n",
            "Requirement already satisfied, skipping upgrade: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from bs4->deepspeech-training==0.9.0a10) (4.6.3)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->deepspeech-training==0.9.0a10) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->deepspeech-training==0.9.0a10) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->deepspeech-training==0.9.0a10) (2020.11.8)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->deepspeech-training==0.9.0a10) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->deepspeech-training==0.9.0a10) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->deepspeech-training==0.9.0a10) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from numba==0.47.0->deepspeech-training==0.9.0a10) (49.6.0)\n",
            "Requirement already satisfied, skipping upgrade: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa->deepspeech-training==0.9.0a10) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa->deepspeech-training==0.9.0a10) (2.1.9)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa->deepspeech-training==0.9.0a10) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa->deepspeech-training==0.9.0a10) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile->deepspeech-training==0.9.0a10) (1.14.3)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.0a10) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.0a10) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.0a10) (0.2.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 42.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.0a10) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.0a10) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.0a10) (1.33.2)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 45.5 MB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.0a10) (0.34.2)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.0a10) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.9.0a10) (3.3.0)\n",
            "Collecting python-editor>=0.3\n",
            "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.1.3-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 3.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: PyYAML>=3.12 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna->deepspeech-training==0.9.0a10) (3.13)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.5.1-py2.py3-none-any.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 47.1 MB/s \n",
            "\u001b[?25hCollecting cmd2!=0.8.3,>=0.8.0\n",
            "  Downloading cmd2-1.4.0-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 49.1 MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.3.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.7 MB/s \n",
            "\u001b[?25hCollecting PrettyTable<0.8,>=0.7.2\n",
            "  Downloading prettytable-0.7.2.tar.bz2 (21 kB)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna->deepspeech-training==0.9.0a10) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile->deepspeech-training==0.9.0a10) (2.20)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4->deepspeech-training==0.9.0a10) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4->deepspeech-training==0.9.0a10) (3.3.3)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.4->deepspeech-training==0.9.0a10) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic->optuna->deepspeech-training==0.9.0a10) (1.1.1)\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=1.6.0; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna->deepspeech-training==0.9.0a10) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: attrs>=16.3.0 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna->deepspeech-training==0.9.0a10) (20.3.0)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.1.tar.gz (20 kB)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna->deepspeech-training==0.9.0a10) (0.2.5)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=1.6.0; python_version < \"3.8\"->cmd2!=0.8.3,>=0.8.0->cliff->optuna->deepspeech-training==0.9.0a10) (3.4.0)\n",
            "Building wheels for collected packages: opuslib, optuna, gast, PrettyTable, pyperclip\n",
            "  Building wheel for opuslib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for opuslib: filename=opuslib-2.0.0-py3-none-any.whl size=11009 sha256=a55cce519c44d5bb6633b2ec4a8f913d09825e56bcf61c0732f5063ad2630e9b\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/01/88/37797e9e9d157a33eefed22a46aa0bf5044effcec6a9181e41\n",
            "  Building wheel for optuna (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for optuna: filename=optuna-2.3.0-py3-none-any.whl size=359760 sha256=9e537c6ccea829bc6cb6dda2042a745ee8cae815440e2f7ab4a9df64bf891414\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/a6/07/3e68f946721e5e7f15395097b477800eff26673717b5e50f5f\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7539 sha256=f5a1795ea13b0104706edb1570f06eed040ed3fff57065c71cd49446de525313\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/a7/b9/0740c7a3a7d1d348f04823339274b90de25fbcd217b2ee1fbe\n",
            "  Building wheel for PrettyTable (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PrettyTable: filename=prettytable-0.7.2-py3-none-any.whl size=13698 sha256=d0ba95759831eda93b7143d3b775451e61310cc26367d5b4a5ce67a1c1de54a4\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/15/c3/5f28b42ae9c81638570b8b7ed654e0f98c5fdc08875869511b\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.1-py3-none-any.whl size=11118 sha256=6d8c57ae55fcd6598d5109a7a5ce3620af40192f4f82d06e8e31dbc7a04ef2e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/27/28/fa23ac551b4fad562edc8d50a4ae1182f31408aae1d6027c39\n",
            "Successfully built opuslib optuna gast PrettyTable pyperclip\n",
            "Installing collected packages: pyxdg, attrdict, semver, opuslib, cmaes, colorlog, python-editor, Mako, alembic, pbr, colorama, pyperclip, cmd2, stevedore, PrettyTable, cliff, optuna, sox, numba, soundfile, ds-ctcdecoder, tensorflow-estimator, tensorboard, gast, keras-applications, tensorflow, deepspeech-training\n",
            "  Attempting uninstall: PrettyTable\n",
            "    Found existing installation: prettytable 2.0.0\n",
            "    Uninstalling prettytable-2.0.0:\n",
            "      Successfully uninstalled prettytable-2.0.0\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.48.0\n",
            "    Uninstalling numba-0.48.0:\n",
            "      Successfully uninstalled numba-0.48.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "  Running setup.py develop for deepspeech-training\n",
            "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
            "\n",
            "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
            "\n",
            "umap-learn 0.4.6 requires numba!=0.47,>=0.46, but you'll have numba 0.47.0 which is incompatible.\n",
            "tensorflow-probability 0.11.0 requires gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Successfully installed Mako-1.1.3 PrettyTable-0.7.2 alembic-1.4.3 attrdict-2.0.1 cliff-3.5.0 cmaes-0.7.0 cmd2-1.4.0 colorama-0.4.4 colorlog-4.6.2 deepspeech-training ds-ctcdecoder-0.9.0a10 gast-0.2.2 keras-applications-1.0.8 numba-0.47.0 optuna-2.3.0 opuslib-2.0.0 pbr-5.5.1 pyperclip-1.8.1 python-editor-1.0.4 pyxdg-0.27 semver-2.13.0 soundfile-0.10.3.post1 sox-1.4.1 stevedore-3.3.0 tensorboard-1.15.0 tensorflow-1.15.4 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAuHrSPm-Bvy",
        "outputId": "e515cd31-4e58-407f-a10a-22f5ae22a295"
      },
      "source": [
        "!sudo apt-get install python3-dev"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python3-dev is already the newest version (3.6.7-1~18.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 14 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNPVMLyz-FiO",
        "outputId": "9be67046-bad3-47e5-dd6d-8bce821222b1"
      },
      "source": [
        "!pip3 uninstall tensorflow\n",
        "!pip3 install 'tensorflow-gpu==1.15.4'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found existing installation: tensorflow 1.15.4\n",
            "Uninstalling tensorflow-1.15.4:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/freeze_graph\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow-1.15.4.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow/*\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow_core/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-1.15.4\n",
            "Collecting tensorflow-gpu==1.15.4\n",
            "  Downloading tensorflow_gpu-1.15.4-cp36-cp36m-manylinux2010_x86_64.whl (411.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 411.0 MB 16 kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.4) (1.0.8)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.4) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.4) (3.12.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.4) (0.2.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.4) (1.18.5)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.4) (1.15.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.4) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.4) (1.12.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.4) (1.15.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.4) (0.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.4) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.4) (0.10.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.4) (0.8.1)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.4) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.4) (1.33.2)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.4) (0.34.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.4) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.15.4) (49.6.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.4) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.4) (3.3.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.4) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.4) (3.4.0)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-1.15.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzwPzFDN-Vut",
        "outputId": "7d52d660-5e06-4794-eb5b-2209ee689992"
      },
      "source": [
        "!make Dockerfile.train"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sed \\\n",
            "\t-e \"s|#DEEPSPEECH_REPO#|https://github.com/mozilla/DeepSpeech.git|g\" \\\n",
            "\t-e \"s|#DEEPSPEECH_SHA#|origin/master|g\" \\\n",
            "\t< Dockerfile.train.tmpl > Dockerfile.train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5l-5zPD-kqt"
      },
      "source": [
        "os.mkdir('fine_tuning_checkpoints')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTo05EUEE5KM",
        "outputId": "112ee51c-63a3-4ba0-aeda-d73413477b26"
      },
      "source": [
        "!python3 DeepSpeech.py --n_hidden 2048 --checkpoint_dir fine_tuning_checkpoints --epochs 100 --train_files audioset/my-dev.csv --dev_files audioset/my-dev.csv --test_files audioset/my-dev.csv --learning_rate 0.0001"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I1207 04:21:42.442367 140118644549504 utils.py:141] NumExpr defaulting to 2 threads.\n",
            "I Loading best validating checkpoint from fine_tuning_checkpoints/best_dev-124\n",
            "I Loading variable from checkpoint: beta1_power\n",
            "I Loading variable from checkpoint: beta2_power\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam_1\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam_1\n",
            "I Loading variable from checkpoint: global_step\n",
            "I Loading variable from checkpoint: layer_1/bias\n",
            "I Loading variable from checkpoint: layer_1/bias/Adam\n",
            "I Loading variable from checkpoint: layer_1/bias/Adam_1\n",
            "I Loading variable from checkpoint: layer_1/weights\n",
            "I Loading variable from checkpoint: layer_1/weights/Adam\n",
            "I Loading variable from checkpoint: layer_1/weights/Adam_1\n",
            "I Loading variable from checkpoint: layer_2/bias\n",
            "I Loading variable from checkpoint: layer_2/bias/Adam\n",
            "I Loading variable from checkpoint: layer_2/bias/Adam_1\n",
            "I Loading variable from checkpoint: layer_2/weights\n",
            "I Loading variable from checkpoint: layer_2/weights/Adam\n",
            "I Loading variable from checkpoint: layer_2/weights/Adam_1\n",
            "I Loading variable from checkpoint: layer_3/bias\n",
            "I Loading variable from checkpoint: layer_3/bias/Adam\n",
            "I Loading variable from checkpoint: layer_3/bias/Adam_1\n",
            "I Loading variable from checkpoint: layer_3/weights\n",
            "I Loading variable from checkpoint: layer_3/weights/Adam\n",
            "I Loading variable from checkpoint: layer_3/weights/Adam_1\n",
            "I Loading variable from checkpoint: layer_5/bias\n",
            "I Loading variable from checkpoint: layer_5/bias/Adam\n",
            "I Loading variable from checkpoint: layer_5/bias/Adam_1\n",
            "I Loading variable from checkpoint: layer_5/weights\n",
            "I Loading variable from checkpoint: layer_5/weights/Adam\n",
            "I Loading variable from checkpoint: layer_5/weights/Adam_1\n",
            "I Loading variable from checkpoint: layer_6/bias\n",
            "I Loading variable from checkpoint: layer_6/bias/Adam\n",
            "I Loading variable from checkpoint: layer_6/bias/Adam_1\n",
            "I Loading variable from checkpoint: layer_6/weights\n",
            "I Loading variable from checkpoint: layer_6/weights/Adam\n",
            "I Loading variable from checkpoint: layer_6/weights/Adam_1\n",
            "I Loading variable from checkpoint: learning_rate\n",
            "I STARTING Optimization\n",
            "Epoch 0 |   Training | Elapsed Time: 0:00:06 | Steps: 4 | Loss: 112.697592      \n",
            "Epoch 0 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 109.460602 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 109.460602 to: fine_tuning_checkpoints/best_dev-128\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 1 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 110.267534      \n",
            "Epoch 1 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 106.019690 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 106.019690 to: fine_tuning_checkpoints/best_dev-132\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 2 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 107.902964      \n",
            "Epoch 2 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 102.453989 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 102.453989 to: fine_tuning_checkpoints/best_dev-136\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 3 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 105.335152      \n",
            "Epoch 3 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 99.974045 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 99.974045 to: fine_tuning_checkpoints/best_dev-140\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 4 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 102.393711      \n",
            "Epoch 4 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 97.439548 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 97.439548 to: fine_tuning_checkpoints/best_dev-144\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 5 |   Training | Elapsed Time: 0:00:05 | Steps: 4 | Loss: 99.778122       \n",
            "Epoch 5 | Validation | Elapsed Time: 0:00:02 | Steps: 4 | Loss: 94.607918 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 94.607918 to: fine_tuning_checkpoints/best_dev-148\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 6 |   Training | Elapsed Time: 0:00:05 | Steps: 4 | Loss: 97.663300       \n",
            "Epoch 6 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 92.515600 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 92.515600 to: fine_tuning_checkpoints/best_dev-152\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 7 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 93.800064       \n",
            "Epoch 7 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 90.566027 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 90.566027 to: fine_tuning_checkpoints/best_dev-156\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 8 |   Training | Elapsed Time: 0:00:05 | Steps: 4 | Loss: 91.970257       \n",
            "Epoch 8 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 87.509163 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 87.509163 to: fine_tuning_checkpoints/best_dev-160\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 9 |   Training | Elapsed Time: 0:00:05 | Steps: 4 | Loss: 89.830612       \n",
            "Epoch 9 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 85.849900 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 85.849900 to: fine_tuning_checkpoints/best_dev-164\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 10 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 90.434240      \n",
            "Epoch 10 | Validation | Elapsed Time: 0:00:05 | Steps: 4 | Loss: 89.848665 | Dataset: audioset/my-dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 11 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 90.966648      \n",
            "Epoch 11 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 94.932610 | Dataset: audioset/my-dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 12 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 97.033375      \n",
            "Epoch 12 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 87.561865 | Dataset: audioset/my-dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 13 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 90.527744      \n",
            "Epoch 13 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 85.099676 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 85.099676 to: fine_tuning_checkpoints/best_dev-180\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 14 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 86.191147      \n",
            "Epoch 14 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 83.843449 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 83.843449 to: fine_tuning_checkpoints/best_dev-184\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 15 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 83.429634      \n",
            "Epoch 15 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 81.428234 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 81.428234 to: fine_tuning_checkpoints/best_dev-188\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 16 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 81.093655      \n",
            "Epoch 16 | Validation | Elapsed Time: 0:00:02 | Steps: 4 | Loss: 77.538767 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 77.538767 to: fine_tuning_checkpoints/best_dev-192\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 17 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 79.829744      \n",
            "Epoch 17 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 76.018215 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 76.018215 to: fine_tuning_checkpoints/best_dev-196\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 18 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 77.382852      \n",
            "Epoch 18 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 73.134530 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 73.134530 to: fine_tuning_checkpoints/best_dev-200\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 19 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 74.416508      \n",
            "Epoch 19 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 70.937560 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 70.937560 to: fine_tuning_checkpoints/best_dev-204\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 20 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 73.065120      \n",
            "Epoch 20 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 69.753944 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 69.753944 to: fine_tuning_checkpoints/best_dev-208\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 21 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 73.717009      \n",
            "Epoch 21 | Validation | Elapsed Time: 0:00:02 | Steps: 4 | Loss: 68.098318 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 68.098318 to: fine_tuning_checkpoints/best_dev-212\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 22 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 71.255803      \n",
            "Epoch 22 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 68.435020 | Dataset: audioset/my-dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 23 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 70.550719      \n",
            "Epoch 23 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 69.401409 | Dataset: audioset/my-dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 24 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 70.217390      \n",
            "Epoch 24 | Validation | Elapsed Time: 0:00:02 | Steps: 4 | Loss: 63.954464 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 63.954464 to: fine_tuning_checkpoints/best_dev-224\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 25 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 65.602377      \n",
            "Epoch 25 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 62.094871 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 62.094871 to: fine_tuning_checkpoints/best_dev-228\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 26 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 65.747807      \n",
            "Epoch 26 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 59.641724 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 59.641724 to: fine_tuning_checkpoints/best_dev-232\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 27 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 64.118539      \n",
            "Epoch 27 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 61.450473 | Dataset: audioset/my-dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 28 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 63.901635      \n",
            "Epoch 28 | Validation | Elapsed Time: 0:00:03 | Steps: 4 | Loss: 59.435260 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 59.435260 to: fine_tuning_checkpoints/best_dev-240\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 29 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 62.836950      \n",
            "Epoch 29 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 59.089639 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 59.089639 to: fine_tuning_checkpoints/best_dev-244\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 30 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 62.770697      \n",
            "Epoch 30 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 59.218701 | Dataset: audioset/my-dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 31 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 64.624094      \n",
            "Epoch 31 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 57.455231 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 57.455231 to: fine_tuning_checkpoints/best_dev-252\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 32 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 63.566303      \n",
            "Epoch 32 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 59.154795 | Dataset: audioset/my-dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 33 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 63.524232      \n",
            "Epoch 33 | Validation | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 61.850481 | Dataset: audioset/my-dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 34 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 63.125863      \n",
            "Epoch 34 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 57.643993 | Dataset: audioset/my-dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 35 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 57.976413      \n",
            "Epoch 35 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 59.799923 | Dataset: audioset/my-dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 36 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 59.887279      \n",
            "Epoch 36 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 55.743260 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 55.743260 to: fine_tuning_checkpoints/best_dev-272\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 37 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 58.296735      \n",
            "Epoch 37 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 55.753777 | Dataset: audioset/my-dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 38 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 56.911355      \n",
            "Epoch 38 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 51.005620 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 51.005620 to: fine_tuning_checkpoints/best_dev-280\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 39 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 52.059605      \n",
            "Epoch 39 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 49.919634 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 49.919634 to: fine_tuning_checkpoints/best_dev-284\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 40 |   Training | Elapsed Time: 0:00:05 | Steps: 4 | Loss: 52.435201      \n",
            "Epoch 40 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 48.422324 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 48.422324 to: fine_tuning_checkpoints/best_dev-288\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 41 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 49.971389      \n",
            "Epoch 41 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 46.377777 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 46.377777 to: fine_tuning_checkpoints/best_dev-292\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 42 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 48.619745      \n",
            "Epoch 42 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 46.156010 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 46.156010 to: fine_tuning_checkpoints/best_dev-296\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 43 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 51.177688      \n",
            "Epoch 43 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 47.612408 | Dataset: audioset/my-dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 44 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 48.943128      \n",
            "Epoch 44 | Validation | Elapsed Time: 0:00:02 | Steps: 4 | Loss: 45.367234 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 45.367234 to: fine_tuning_checkpoints/best_dev-304\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 45 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 46.303675      \n",
            "Epoch 45 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 43.268905 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 43.268905 to: fine_tuning_checkpoints/best_dev-308\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 46 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 47.019780      \n",
            "Epoch 46 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 45.102518 | Dataset: audioset/my-dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 47 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 49.713068      \n",
            "Epoch 47 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 42.870476 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 42.870476 to: fine_tuning_checkpoints/best_dev-316\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 48 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 49.205667      \n",
            "Epoch 48 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 47.551458 | Dataset: audioset/my-dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 49 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 47.718378      \n",
            "Epoch 49 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 48.400659 | Dataset: audioset/my-dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 50 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 46.708076      \n",
            "Epoch 50 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 43.219961 | Dataset: audioset/my-dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 51 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 47.429867      \n",
            "Epoch 51 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 46.614092 | Dataset: audioset/my-dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 52 |   Training | Elapsed Time: 0:00:06 | Steps: 4 | Loss: 49.007662      \n",
            "Epoch 52 | Validation | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 43.018979 | Dataset: audioset/my-dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 53 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 44.853976      \n",
            "Epoch 53 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 40.782582 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 40.782582 to: fine_tuning_checkpoints/best_dev-340\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 54 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 41.262213      \n",
            "Epoch 54 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 38.805697 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 38.805697 to: fine_tuning_checkpoints/best_dev-344\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 55 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 38.767359      \n",
            "Epoch 55 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 37.534108 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 37.534108 to: fine_tuning_checkpoints/best_dev-348\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 56 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 37.735466      \n",
            "Epoch 56 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 35.784006 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 35.784006 to: fine_tuning_checkpoints/best_dev-352\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 57 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 36.584438      \n",
            "Epoch 57 | Validation | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 34.988795 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 34.988795 to: fine_tuning_checkpoints/best_dev-356\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 58 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 34.919964      \n",
            "Epoch 58 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 32.582578 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 32.582578 to: fine_tuning_checkpoints/best_dev-360\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 59 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 33.506025      \n",
            "Epoch 59 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 31.316966 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 31.316966 to: fine_tuning_checkpoints/best_dev-364\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 60 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 31.618616      \n",
            "Epoch 60 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 29.374834 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 29.374834 to: fine_tuning_checkpoints/best_dev-368\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 61 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 30.276593      \n",
            "Epoch 61 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 29.372300 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 29.372300 to: fine_tuning_checkpoints/best_dev-372\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 62 |   Training | Elapsed Time: 0:00:05 | Steps: 4 | Loss: 31.871708      \n",
            "Epoch 62 | Validation | Elapsed Time: 0:00:05 | Steps: 4 | Loss: 30.005122 | Dataset: audioset/my-dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 63 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 35.396372      \n",
            "Epoch 63 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 33.100526 | Dataset: audioset/my-dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 64 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 36.110980      \n",
            "Epoch 64 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 34.010507 | Dataset: audioset/my-dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 65 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 37.591482      \n",
            "Epoch 65 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 29.239117 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 29.239117 to: fine_tuning_checkpoints/best_dev-388\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 66 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 35.825494      \n",
            "Epoch 66 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 34.499151 | Dataset: audioset/my-dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 67 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 33.916539      \n",
            "Epoch 67 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 30.342997 | Dataset: audioset/my-dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 68 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 32.596897      \n",
            "Epoch 68 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 28.421890 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 28.421890 to: fine_tuning_checkpoints/best_dev-400\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 69 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 30.103982      \n",
            "Epoch 69 | Validation | Elapsed Time: 0:00:02 | Steps: 4 | Loss: 27.676016 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 27.676016 to: fine_tuning_checkpoints/best_dev-404\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 70 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 27.550397      \n",
            "Epoch 70 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 26.854891 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 26.854891 to: fine_tuning_checkpoints/best_dev-408\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 71 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 28.963007      \n",
            "Epoch 71 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 28.159652 | Dataset: audioset/my-dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 72 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 26.813895      \n",
            "Epoch 72 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 24.917030 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 24.917030 to: fine_tuning_checkpoints/best_dev-416\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 73 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 25.072075      \n",
            "Epoch 73 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 23.388833 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 23.388833 to: fine_tuning_checkpoints/best_dev-420\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 74 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 23.582487      \n",
            "Epoch 74 | Validation | Elapsed Time: 0:00:02 | Steps: 4 | Loss: 23.227337 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 23.227337 to: fine_tuning_checkpoints/best_dev-424\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 75 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 24.127851      \n",
            "Epoch 75 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 24.109586 | Dataset: audioset/my-dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 76 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 25.659494      \n",
            "Epoch 76 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 24.146289 | Dataset: audioset/my-dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 77 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 25.593096      \n",
            "Epoch 77 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 23.196042 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 23.196042 to: fine_tuning_checkpoints/best_dev-436\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 78 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 27.463365      \n",
            "Epoch 78 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 29.524324 | Dataset: audioset/my-dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 79 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 31.855458      \n",
            "Epoch 79 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 26.762057 | Dataset: audioset/my-dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 80 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 29.207854      \n",
            "Epoch 80 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 26.111697 | Dataset: audioset/my-dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 81 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 29.969475      \n",
            "Epoch 81 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 24.420830 | Dataset: audioset/my-dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 82 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 25.595826      \n",
            "Epoch 82 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 23.676955 | Dataset: audioset/my-dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 83 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 24.071752      \n",
            "Epoch 83 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 21.016461 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 21.016461 to: fine_tuning_checkpoints/best_dev-460\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 84 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 21.909319      \n",
            "Epoch 84 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 20.424057 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 20.424057 to: fine_tuning_checkpoints/best_dev-464\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 85 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 20.585649      \n",
            "Epoch 85 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 19.601048 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 19.601048 to: fine_tuning_checkpoints/best_dev-468\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 86 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 20.461608      \n",
            "Epoch 86 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 17.894042 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 17.894042 to: fine_tuning_checkpoints/best_dev-472\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 87 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 18.272864      \n",
            "Epoch 87 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 17.592173 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 17.592173 to: fine_tuning_checkpoints/best_dev-476\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 88 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 17.742173      \n",
            "Epoch 88 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 16.218727 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 16.218727 to: fine_tuning_checkpoints/best_dev-480\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 89 |   Training | Elapsed Time: 0:00:05 | Steps: 4 | Loss: 16.777341      \n",
            "Epoch 89 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 15.480325 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 15.480325 to: fine_tuning_checkpoints/best_dev-484\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 90 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 16.452707      \n",
            "Epoch 90 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 14.891226 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 14.891226 to: fine_tuning_checkpoints/best_dev-488\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 91 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 15.153432      \n",
            "Epoch 91 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 14.127874 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 14.127874 to: fine_tuning_checkpoints/best_dev-492\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 92 |   Training | Elapsed Time: 0:00:05 | Steps: 4 | Loss: 14.692233      \n",
            "Epoch 92 | Validation | Elapsed Time: 0:00:05 | Steps: 4 | Loss: 13.789911 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 13.789911 to: fine_tuning_checkpoints/best_dev-496\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 93 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 14.525612      \n",
            "Epoch 93 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 13.093029 | Dataset: audioset/my-dev.csv\n",
            "I Saved new best validating model with loss 13.093029 to: fine_tuning_checkpoints/best_dev-500\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 94 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 14.450631      \n",
            "Epoch 94 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 13.555604 | Dataset: audioset/my-dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 95 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 15.017138      \n",
            "Epoch 95 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 13.147513 | Dataset: audioset/my-dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 96 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 15.264828      \n",
            "Epoch 96 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 14.674234 | Dataset: audioset/my-dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 97 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 21.054640      \n",
            "Epoch 97 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 18.371953 | Dataset: audioset/my-dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 98 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 21.441113      \n",
            "Epoch 98 | Validation | Elapsed Time: 0:00:01 | Steps: 4 | Loss: 18.846521 | Dataset: audioset/my-dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 99 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 24.266626      \n",
            "Epoch 99 | Validation | Elapsed Time: 0:00:02 | Steps: 4 | Loss: 28.580602 | Dataset: audioset/my-dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "I FINISHED optimization in 0:37:48.431449\n",
            "I Loading best validating checkpoint from fine_tuning_checkpoints/best_dev-500\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
            "I Loading variable from checkpoint: global_step\n",
            "I Loading variable from checkpoint: layer_1/bias\n",
            "I Loading variable from checkpoint: layer_1/weights\n",
            "I Loading variable from checkpoint: layer_2/bias\n",
            "I Loading variable from checkpoint: layer_2/weights\n",
            "I Loading variable from checkpoint: layer_3/bias\n",
            "I Loading variable from checkpoint: layer_3/weights\n",
            "I Loading variable from checkpoint: layer_5/bias\n",
            "I Loading variable from checkpoint: layer_5/weights\n",
            "I Loading variable from checkpoint: layer_6/bias\n",
            "I Loading variable from checkpoint: layer_6/weights\n",
            "Testing model on audioset/my-dev.csv\n",
            "Test epoch | Steps: 4 | Elapsed Time: 0:00:10                                   \n",
            "Test on audioset/my-dev.csv - WER: 0.212766, CER: 0.098131, loss: 13.093028\n",
            "--------------------------------------------------------------------------------\n",
            "Best WER: \n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.083333, CER: 0.057692, loss: 8.021577\n",
            " - wav: file:///content/DeepSpeech/audioset/fifth.wav\n",
            " - src: \"today is a good day and i have some fries for dinner\"\n",
            " - res: \"today is a good day and i have some fries  dinner\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.083333, CER: 0.037037, loss: 5.045732\n",
            " - wav: file:///content/DeepSpeech/audioset/seventh.wav\n",
            " - src: \"hello we went to the macy to see parade at time square\"\n",
            " - res: \"hello we went to the macy to see parade at ti square\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.166667, CER: 0.054545, loss: 10.370481\n",
            " - wav: file:///content/DeepSpeech/audioset/eighth.wav\n",
            " - src: \"we went to the north pole and we didn't see any penguin\"\n",
            " - res: \"we went to the north pole and we didn't eany penguin\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.545455, CER: 0.245283, loss: 28.934326\n",
            " - wav: file:///content/DeepSpeech/audioset/sixth.wav\n",
            " - src: \"hello this is a good night and we watched some movies\"\n",
            " - res: \"hello this is ood night and watchemovies\"\n",
            "--------------------------------------------------------------------------------\n",
            "Median WER: \n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.083333, CER: 0.057692, loss: 8.021577\n",
            " - wav: file:///content/DeepSpeech/audioset/fifth.wav\n",
            " - src: \"today is a good day and i have some fries for dinner\"\n",
            " - res: \"today is a good day and i have some fries  dinner\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.083333, CER: 0.037037, loss: 5.045732\n",
            " - wav: file:///content/DeepSpeech/audioset/seventh.wav\n",
            " - src: \"hello we went to the macy to see parade at time square\"\n",
            " - res: \"hello we went to the macy to see parade at ti square\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.166667, CER: 0.054545, loss: 10.370481\n",
            " - wav: file:///content/DeepSpeech/audioset/eighth.wav\n",
            " - src: \"we went to the north pole and we didn't see any penguin\"\n",
            " - res: \"we went to the north pole and we didn't eany penguin\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.545455, CER: 0.245283, loss: 28.934326\n",
            " - wav: file:///content/DeepSpeech/audioset/sixth.wav\n",
            " - src: \"hello this is a good night and we watched some movies\"\n",
            " - res: \"hello this is ood night and watchemovies\"\n",
            "--------------------------------------------------------------------------------\n",
            "Worst WER: \n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.083333, CER: 0.057692, loss: 8.021577\n",
            " - wav: file:///content/DeepSpeech/audioset/fifth.wav\n",
            " - src: \"today is a good day and i have some fries for dinner\"\n",
            " - res: \"today is a good day and i have some fries  dinner\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.083333, CER: 0.037037, loss: 5.045732\n",
            " - wav: file:///content/DeepSpeech/audioset/seventh.wav\n",
            " - src: \"hello we went to the macy to see parade at time square\"\n",
            " - res: \"hello we went to the macy to see parade at ti square\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.166667, CER: 0.054545, loss: 10.370481\n",
            " - wav: file:///content/DeepSpeech/audioset/eighth.wav\n",
            " - src: \"we went to the north pole and we didn't see any penguin\"\n",
            " - res: \"we went to the north pole and we didn't eany penguin\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.545455, CER: 0.245283, loss: 28.934326\n",
            " - wav: file:///content/DeepSpeech/audioset/sixth.wav\n",
            " - src: \"hello this is a good night and we watched some movies\"\n",
            " - res: \"hello this is ood night and watchemovies\"\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}